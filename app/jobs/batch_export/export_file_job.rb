module BatchExport
  class ExportFileJob < ActiveJob::Base
    # require 'down/wget'
    require 'bagit'

    include BatchExport::SharedMethods

    # Exports files as bags (.7z files with file, file set, and work metadata) that get
    # moved to long-term preservation storage in case of a major earthquake or other natural
    # disaster that destroys local backups.
    #
    # Bag structure:
    #   Bag/folder named after file set id
    #     |__ data (folder/dir)
    #           |__objects (folder/dir)
    #                 |__file_set_id.ext - latest version of a file (downloaded from Fedora)
    #                 |__bitstream_file_set_id - bitstream of file (without extension)
    #           |__metadata.txt - file metadata (e.g. mime type, duration, date of last fixity check)
    #     |__bag-info.txt - info about bagging algorithm, generated automatically by bagit gem
    #     |__collection_uuids_and_titles.txt - the unique ID and title of the collection a file set is in
    #     |__manifest-sha.txt - SHA1 checksums for files inside the data folder
    #     |__tagmanifest-sha1.txt - SHA1 checksums for manifest-sha1.txt, bag-info.txt, bagit.txt
    #                               (automatically generated by bagit gem)
    #     |__tagmanifest-md5.txt - MD5 checksums for the same files listed above
    #     |__work_and_file_set_metadata.csv - CSV representation of file set and work metadata
    #                                         (e.g. creator, rights_statement)
    #     |__[file set id].txt - The full text contents (transcript) of the file if available

    # Where to temporarily store the bags until they're uploaded to OLRC
    EXPORT_DIR = "/cache/vault_tmp/exports"
    # The name of the OLRC container to upload to
    CONTAINER_NAME = "vault"

    def perform(file_set, dirname = EXPORT_DIR)
      bag_dir = "#{dirname}/#{file_set.id}"
      # file_set = FileSet.find(file_set)
      GC.compact

      # Omit thumbnails for primarily audio/video works
      return if skip_thumbnail?(file_set) # or already_uploaded?("#{file_set.id}.7z")

      # Create a new directory named after the file set id
      FileUtils.mkdir_p(bag_dir) && FileUtils.mkdir_p("#{bag_dir}/data")
      download_objects(file_set, bag_dir)
      extract_text(file_set, bag_dir)
      write_file_metadata(file_set, "#{bag_dir}/data/metadata.txt")
      CdmMigrator::CsvExportService.new([GenericWork]).write_to_csv([file_set.parent_id],"#{bag_dir}/work_and_file_set_metadata.csv")
      write_collection_ids_and_titles(file_set.parent_id, bag_dir)

      bag = BagIt::Bag.new bag_dir
      # Generate a checksum for the bag
      bag.manifest!(algo: 'sha1')
      # Compress everything into .7z format. Requires p7zip library; apt install p7zip-full
      `7za a -md=32m #{bag_dir}.7z #{bag_dir}/*` # -mmt2 
      # Clean up after ourselves
      FileUtils.rm_rf bag_dir
      # Files less than 5kb are likely an error
      upload_to_olrc("#{bag_dir}.7z") if File.size("#{bag_dir}.7z") / 1024 >= 5
      # Start "garbage collection" to decrease memory load
      GC.start
    end

    private

    def upload_to_olrc(filename)
      # Upload in 4GB chunks if file is over 4GB
      output = upload_command(filename)
      if output.match?(/#{File.basename(filename)}/)
      # If succeeded
        FileUtils.rm(filename)
      else
        raise "Uploading to OLRC failed with message: #{output}"
      end
    end

    def upload_command(filename)
      `swift upload -S 4294967296 --skip-identical #{CONTAINER_NAME} #{filename} --object-name #{File.basename(filename)}`
    end

    def already_uploaded?(filename)
      (`swift list --prefix #{filename} #{CONTAINER_NAME} --lh`).match?(/#{filename}/)
    end

    def write_file_metadata(file_set, filename)
      presenter = Hyrax::FileSetPresenter.new(SolrDocument.find(file_set.id),"admin")
      puts presenter
      metadata = presenter.characterization_metadata.transform_keys(&:to_s)
      puts metadata
      # "original_checksum" => "md5_checksum"
      metadata["md5_checksum"] = metadata.delete("original_checksum")
      if file_set.import_url.present?
        metadata['path_on_local_drive'] = file_set.import_url.gsub("file:///usr/local/rails/vault/tmp/uploads/local_files", "Q:").gsub("/","\\")
      else
        metadata['path_on_local_drive'] = "Can't find location on Q"
      end
      metadata['fixity_check_status'] = ActionView::Base.full_sanitizer.sanitize(presenter.fixity_check_status)
      # Build an array of lines to write to the text file
      lines = metadata.to_a.map { |arr| arr.join(": ") }
      File.open(filename, "a") do |f|
        f.puts(lines)
      end
    end

    def extract_text(file_set, bag_dir)
      if (file_set.extracted_text and file_set.extracted_text.content.present?) || file_set.transcript.present?
        if file_set.extracted_text
          text = file_set.extracted_text.content
        else
          text = file_set.transcript.clone.join("")
        end
        File.open("#{bag_dir}/#{file_set.id}.txt","wb") { |file| file.write(text) }
      end
    end

    def download_objects(file_set, dirname)
      FileUtils.mkdir_p("#{dirname}/data/objects")
      object_dir = "#{dirname}/data/objects"
      id = file_set.id
      ext = File.extname(File.basename(file_set.files.first.file_name.first))
      user = ActiveFedora.fedora_config.credentials[:user]
      password = ActiveFedora.fedora_config.credentials[:password]

      `curl #{file_set.files.first.uri.to_s} -u #{user}:#{password} -o #{object_dir}/#{id}#{ext} -L -O -J`
      FileUtils.copy_file("#{object_dir}/#{id}#{ext}", "#{object_dir}/bitstream_#{id}")
    end

    def host_url
      if Settings.multitenancy.enabled
        "https://#{Account.find_by(tenant: Apartment::Tenant.current).cname}"
      else
        "http://#{Settings.multitenancy.host}"
      end
    end

    def write_collection_ids_and_titles(parent_id, bag_dir)
      if ActiveFedora::Base.find(parent_id).member_of_collection_ids.any?
        File.open("#{bag_dir}/collection_uuids_and_titles.txt", "a") do |file|
          doc = SolrDocument.find(parent_id)
          doc['member_of_collection_ids_ssim'].each do |id, index|
            file.puts "#{id} \t #{doc['member_of_collections_ssim'][index.to_i]}"
          end
        end
      end
    end

  end
end