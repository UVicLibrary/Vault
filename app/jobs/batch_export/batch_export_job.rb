class BatchExportJob < ActiveJob::Base
  require 'down/wget'
  require 'bagit'
  require_relative 'export_file_set_and_work_metadata'

  # Exports files as bags (.7z files with file, file set, and work metadata) that get
  # moved to long-term preservation storage in case of a major earthquake or other natural
  # disaster that destroys local backups.
  #
  # Bag structure:
  #   Bag/folder named after file set id
  #     |__ data (folder/dir)
  #           |__objects (folder/dir)
  #                 |__file_set_id.ext - latest version of a file (downloaded from Fedora)
  #                 |__bitstream_file_set_id - bitstream of file (without extension)
  #           |__metadata.txt - file metadata (e.g. mime type, duration, date of last fixity check)
  #     |__bag-info.txt - info about bagging algorithm, generated automatically by bagit gem
  #     |__collection_uuids_and_titles.txt - the unique ID and title of the collection a file set is in
  #     |__manifest-sha.txt - SHA1 checksums for files inside the data folder
  #     |__tagmanifest-sha1.txt - SHA1 checksums for manifest-sha1.txt, bag-info.txt, bagit.txt
  #                               (automatically generated by bagit gem)
  #     |__tagmanifest-md5.txt - MD5 checksums for the same files listed above
  #     |__work_and_file_set_metadata.csv - CSV representation of file set and work metadata
  #                                         (e.g. creator, rights_statement)
  #     |__[file set id].txt - The full text contents (transcript) of the file if available

  # @param[Array <GenericWork> ] works - the works to export
  # @param[String] dirname - the directory to export to
  def perform(works, dirname = "/mnt/LSYS01/vault/export_files")
    Dir.chdir(dirname) do
      works.each do |work|
        # Don't export if work is in a test collection
        next if work.collection.any? { |title| title.downcase.include? "test" }
        work.file_sets.each do |file_set|
          # Create a new directory named after the file set id
          bag_dir = "#{file_set.id}"
          next if File.file? "#{bag_dir}.7z" or File.file? "/mnt/narwhal/#{bag_dir}.7z" or skip_thumbnail?(file_set)
          FileUtils.mkdir_p(bag_dir)
          Dir.chdir(bag_dir) do
            FileUtils.mkdir_p("data")
            extract_text(file_set)
            write_file_metadata(file_set, Dir.pwd,"data/metadata.txt")
            write_file_set_and_work_metadata(file_set, "work_and_file_set_metadata.csv")
            write_collection_ids_and_titles(file_set)
          end
          bag = BagIt::Bag.new bag_dir
          # Generate a checksum for the bag
          bag.manifest!(algo: 'sha1')
          # Compress everything into .7z format
          `7z a #{file_set.id} ./#{file_set.id}/*`
        end
      end
    end
  end

  private
  
  def write_file_metadata(file_set, bag_dir, filename)
    presenter = Hyrax::FileSetPresenter.new(SolrDocument.find(file_set.id),"admin")
    puts presenter
    metadata = presenter.characterization_metadata.transform_keys(&:to_s)
    puts metadata
    # "original_checksum" => "md5_checksum"
    metadata["md5_checksum"] = metadata.delete("original_checksum")
    if file_set.import_url.present?
      metadata['path_on_Q'] = file_set.import_url.gsub("file:///usr/local/rails/vault/tmp/uploads/local_files", "Q:").gsub("/","\\")
    else
      metadata['path_on_Q'] = "Can't find location on Q"
    end
    metadata['fixity_check_status'] = ActionView::Base.full_sanitizer.sanitize(presenter.fixity_check_status)
    # Build an array of lines to write to the text file
    lines = metadata.to_a.map { |arr| arr.join(": ") }
    File.open(filename, "a") do |f|
      f.puts(lines)
    end
  end

  def extract_text(file_set)
    if (file_set.extracted_text and file_set.extracted_text.content.present?) || file_set.transcript.present?
      if file_set.extracted_text
        text = file_set.extracted_text.content
      else
        text = file_set.transcript.clone.join("")
      end
      File.open("#{file_set.id}.txt","wb") { |file| file.write(text) }
    end
  end

  def download_objects(file_set)
    FileUtils.mkdir_p('data/objects')
    Dir.chdir('data/objects') do
      id = file_set.id
      url = "https://vault.library.uvic.ca/downloads/#{id}"
      ext = File.extname(File.basename(file_set.files.first.file_name.first))
      Down::Wget.download(url, :no_check_certificate, destination: "bitstream_#{file_set.id}")
      FileUtils.copy_file("bitstream_#{id}", "#{id}#{ext}")
    end
  end

  def write_collection_ids_and_titles(file_set)
    File.open("collection_uuids_and_titles.txt", "a") do |file|
      parent = file_set.parent
      parent.member_of_collection_ids.each do |c_id|
        file.puts "#{c_id} \t #{Collection.find(c_id).title.first}"
      end
    end
  end

  def skip_thumbnail?(file_set)
    # If file set is a thumbnail but not the parent's representative AND
    # the file set is an image AND
    # the representative is not an image
    parent = file_set.parent
    (file_set == parent.thumbnail && file_set != parent.representative) &&
      (file_set.image? && !parent.representative.image?)
  end

  # @return a DateTime object
  def start_date
    (Date.today.beginning_of_month - 6.months).midnight.strftime("%FT%H:%M:%SZ")
  end

  # @return a DateTime object
  def end_date
    (Date.today.beginning_of_month - 3.months).midnight.strftime("%FT%H:%M:%SZ")
  end

  # @return [Array < GenericWork >] array of works to pass to fixity check
  def get_recent_works
    # Get all works uploaded between the start date and end date
    solr = RSolr.connect url: Account.find_by(tenant: Apartment::Tenant.current).solr_endpoint.url
    response = solr.get 'select', params: {
      q: "*:*",
      fq: ["has_model_ssim:GenericWork","system_create_dtsi:[#{start_date} TO #{end_date}}"],
      rows: 5000,
      fl: "id"
    }
    response['response']['docs'].map { |k,_| GenericWork.find(k['id']) }
  end

end
